# Auditor√≠a Profunda del M√≥dulo de Ingesta IoT

**Fecha:** 2026-02-02  
**Autor:** Cascade  
**Objetivo:** Diagn√≥stico honesto de calidad, contratos, resiliencia, rendimiento y estructura

---

# üìä RESUMEN EJECUTIVO

| Categor√≠a | Estado | Riesgo |
|-----------|--------|--------|
| Calidad de C√≥digo | ‚ö†Ô∏è MEDIO | Archivos >180 l√≠neas, tipado parcial |
| Contratos de Datos | ‚ö†Ô∏è MEDIO | DTOs inconsistentes entre canales |
| Resiliencia | üî¥ ALTO | Sin retry, sin idempotencia, sin deduplicaci√≥n |
| Rendimiento | ‚ö†Ô∏è MEDIO | Procesamiento s√≠ncrono, parsing repetido |
| Estructura | ‚ö†Ô∏è MEDIO | Nombres confusos, c√≥digo duplicado |

---

# 1. CALIDAD DE C√ìDIGO

## 1.1 Archivos que Exceden 180 L√≠neas (L√≠mite Establecido)

| Archivo | L√≠neas | Problema |
|---------|--------|----------|
| `metrics/ingestion_metrics.py` | 349 | Demasiadas responsabilidades |
| `ingest/alerts/alert_persistence.py` | 270 | Mezcla persistencia + notificaciones |
| `rate_limiter.py` | 255 | M√∫ltiples estrategias en un archivo |
| `ingest/common/validation.py` | 250 | Validaci√≥n + consultas BD |
| `mqtt/receiver.py` | 246 | Conexi√≥n + procesamiento + stats |
| `ingest/common/delta_utils.py` | 233 | Utilidades + l√≥gica de negocio |
| `device_auth.py` | 208 | Auth + validaci√≥n + queries |
| `batch_inserter.py` | 207 | Buffer + threading + SQL |
| `ingest/common/guards.py` | 202 | Guards + constantes + logging |
| `classification/reading_classifier.py` | 202 | Orquestador sobrecargado |

## 1.2 Funciones con Demasiadas Responsabilidades

### `router.py::classify_and_route()` (l√≠neas 66-195)
```python
# ANTES: Una funci√≥n hace TODO
def classify_and_route(self, sensor_id, value, ...):
    # 1. Validaci√≥n
    guard_result = guard_reading(...)
    # 2. Detecci√≥n de ceros sospechosos
    if is_suspicious_zero_reading(value): ...
    # 3. Ejecuci√≥n de SP
    self._db.execute(text("EXEC sp_insert_reading..."))
    # 4. Publicaci√≥n a broker
    self._broker.publish(reading)
    # 5. Logging de timing
```

**Problema:** Viola SRP. Si falla el broker, ya se ejecut√≥ el SP.

### `validation.py::validate_warning_data()` (l√≠neas 173-241)
```python
# Hace 5 cosas diferentes:
# 1. Verifica estado del sensor
# 2. Consulta umbrales WARNING de BD
# 3. Verifica si valor est√° en rango
# 4. Obtiene √∫ltima lectura
# 5. Eval√∫a delta spike
```

## 1.3 Tipado D√©bil o Ausente

### Problema: `dict` sin tipado espec√≠fico
```python
# ingest/handlers/batch.py:44
def ingest(self, rows: List[dict]) -> int:  # ‚ùå dict gen√©rico
```

**Deber√≠a ser:**
```python
from typing import TypedDict

class ReadingRow(TypedDict):
    sensor_id: int
    value: float
    device_timestamp: Optional[datetime]
    sensor_ts: Optional[float]
    ingested_ts: Optional[float]
    sequence: Optional[int]

def ingest(self, rows: List[ReadingRow]) -> int:  # ‚úÖ Tipado expl√≠cito
```

### Problema: Propiedades que retornan `Optional` sin manejo
```python
# mqtt/validators.py:81-87
@property
def sensor_id_int(self) -> Optional[int]:
    try:
        return int(self.sensor_id)
    except ValueError:
        return None  # ‚ùå Caller debe verificar None
```

## 1.4 Validaciones Incompletas de Payload

### MQTT: Validaci√≥n parcial de metadata
```python
# mqtt/validators.py:43
metadata: dict[str, Any] = Field(default_factory=dict)  # ‚ùå Sin validaci√≥n interna
```

**Problema:** `metadata.sensorType`, `metadata.deviceUuid` pueden ser cualquier cosa.

### HTTP: Sin validaci√≥n de rangos en `SensorReadingUuidIn`
```python
# schemas.py:22-26
class SensorReadingUuidIn(BaseModel):
    sensor_uuid: UUID
    value: float  # ‚ùå Sin validaci√≥n de rango
    sensor_ts: Optional[float] = None  # ‚ùå Sin validaci√≥n de rango temporal
```

## 1.5 Manejo Pobre de Excepciones

### Problema: Catch gen√©rico sin acci√≥n
```python
# ingest/common/validation.py:125-126
except Exception:
    return 0  # ‚ùå Silencia el error, retorna 0

# classification/state_repository.py:39-40
except Exception:
    self._columns_exist = False  # ‚ùå Asume que columnas no existen
```

### Problema: Log sin contexto suficiente
```python
# mqtt/receiver.py:107-109
except Exception as e:
    logger.exception("[MQTT] Start failed: %s", e)  # ‚ùå Sin sensor_id, sin payload
```

## 1.6 Dependencias Mal Inyectadas

### Problema: Creaci√≥n de dependencias dentro de m√©todos
```python
# ingest/common/validation.py:206
state_manager = SensorStateManager(db)  # ‚ùå Crea instancia cada llamada

# ingest/router.py:158
from iot_machine_learning.ml_service.reading_broker import Reading  # ‚ùå Import dentro de m√©todo
```

**Deber√≠a ser:**
```python
class ReadingRouter:
    def __init__(self, db, broker, state_manager: SensorStateManager):
        self._state_manager = state_manager  # ‚úÖ Inyectado
```

---

# 2. CONTRATOS DE DATOS

## 2.1 DTOs Definidos

| Canal | DTO | Ubicaci√≥n | Estado |
|-------|-----|-----------|--------|
| HTTP (legacy) | `SensorReadingIn` | `schemas.py:11` | ‚úÖ B√°sico |
| HTTP (packets) | `DevicePacketIn` | `schemas.py:29` | ‚úÖ Completo |
| MQTT | `MQTTReadingPayload` | `mqtt/validators.py:19` | ‚ö†Ô∏è Parcial |
| Redis Streams | N/A | - | ‚ùå Sin DTO |
| Telemetr√≠a | N/A | - | ‚ùå Sin DTO |

## 2.2 Inconsistencias Entre Canales

### Problema: Nombres de campos diferentes

| Campo | HTTP | MQTT | Redis |
|-------|------|------|-------|
| ID sensor | `sensor_id` (int) | `sensorId` (string) | `sensor_id` (string) |
| Timestamp | `sensor_ts` (float) | `timestamp` (ISO string) | `timestamp` (string) |
| Tipo sensor | N/A | `metadata.sensorType` | `sensor_type` |

### Problema: Tipos diferentes para el mismo dato
```python
# HTTP: sensor_id es int
class SensorReadingIn(BaseModel):
    sensor_id: int = Field(..., ge=1)

# MQTT: sensorId es string, se convierte despu√©s
class MQTTReadingPayload(BaseModel):
    sensor_id: str = Field(..., alias="sensorId")
    
    @property
    def sensor_id_int(self) -> Optional[int]:  # Conversi√≥n manual
```

## 2.3 Validaci√≥n de Estructura

### HTTP: ‚úÖ Pydantic valida estructura
```python
@router.post("/ingest/packets")
def ingest_packet(payload: DevicePacketIn, ...):  # Pydantic valida
```

### MQTT: ‚ö†Ô∏è Validaci√≥n manual despu√©s de parseo
```python
def _on_message(self, client, userdata, msg):
    data = self._parse_json(msg.payload, msg.topic)  # Puede fallar
    result = validate_mqtt_reading(data)  # Validaci√≥n separada
```

### Redis Streams: ‚ùå Sin validaci√≥n
```python
# broker/factory.py - No hay validaci√≥n de estructura al consumir
```

---

# 3. RESILIENCIA

## 3.1 Payload Corrupto

### HTTP: ‚úÖ Pydantic rechaza con 422
### MQTT: ‚ö†Ô∏è Log + descarte silencioso
```python
# mqtt/receiver.py:148-150
data = self._parse_json(msg.payload, msg.topic)
if data is None:
    return  # ‚ùå Descarte silencioso, sin dead letter queue
```

**Riesgo:** P√©rdida de datos sin trazabilidad.

## 3.2 Sensor Duplicado

### ‚ùå Sin deduplicaci√≥n
```python
# No hay verificaci√≥n de msg_id o sequence para evitar duplicados
# Si MQTT reenv√≠a un mensaje, se procesa dos veces
```

**Riesgo:** Lecturas duplicadas en BD, alertas duplicadas.

## 3.3 Timestamp Viejo

### ‚úÖ Validaci√≥n en MQTT
```python
# mqtt/validators.py:66-69
if ts < now - 86400:
    raise ValueError("Timestamp too old (>24 hours)")
```

### ‚ùå Sin validaci√≥n en HTTP
```python
# schemas.py:25
sensor_ts: Optional[float] = None  # Sin validaci√≥n de antig√ºedad
```

## 3.4 Out of Order

### ‚ö†Ô∏è Detecci√≥n sin acci√≥n
```python
# metrics/ingestion_metrics.py:91-97
if sequence <= self.last_sequence:
    result["out_of_order"] = True
    self.out_of_order_count += 1
    logger.warning("OUT_OF_ORDER...")  # Solo log, no reordena
```

**Riesgo:** Delta spike puede dispararse incorrectamente si llegan lecturas desordenadas.

## 3.5 Retry

### ‚ùå Sin retry autom√°tico
```python
# ingest/router.py:144-152
except Exception as e:
    self._logger.exception("INGEST ERROR SP...")
    raise  # ‚ùå Falla inmediata, sin retry
```

**Deber√≠a tener:**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10))
def _execute_sp(self, sensor_id, value, device_ts):
    ...
```

## 3.6 Idempotencia

### ‚ùå Sin soporte
```python
# No hay msg_id tracking
# No hay upsert con ON CONFLICT
# Cada llamada al SP inserta una nueva lectura
```

## 3.7 Deduplicaci√≥n

### ‚ùå Sin implementar
```python
# Deber√≠a existir:
# 1. Cache de msg_id recientes (Redis SET con TTL)
# 2. Verificaci√≥n antes de procesar
# 3. Respuesta idempotente si duplicado
```

---

# 4. RENDIMIENTO

## 4.1 Bloqueos Innecesarios

### Problema: Lock global en BatchInserter
```python
# batch_inserter.py:68
self._lock = threading.Lock()

# batch_inserter.py (en add):
with self._lock:  # ‚ùå Bloquea TODO el buffer
    self._buffer.append(reading)
```

**Deber√≠a usar:** `collections.deque` (thread-safe para append/pop) o `queue.Queue`.

## 4.2 Procesamiento S√≠ncrono Peligroso

### Problema: SP ejecutado s√≠ncronamente en request HTTP
```python
# ingest/router.py:122-137
self._db.execute(text("EXEC sp_insert_reading..."))  # ‚ùå Bloquea request
```

**Riesgo:** Si SP tarda >30s, timeout del cliente.

### Problema: Publicaci√≥n a broker s√≠ncrona
```python
# ingest/router.py:172
self._broker.publish(reading)  # ‚ùå Si Redis lento, bloquea
```

## 4.3 Parsing Repetido

### Problema: Timestamp parseado m√∫ltiples veces
```python
# mqtt/validators.py:59-73 - Parsea en validator
dt = datetime.fromisoformat(v.replace("Z", "+00:00"))

# mqtt/validators.py:118-122 - Parsea OTRA VEZ en property
dt = datetime.fromisoformat(self.timestamp.replace("Z", "+00:00"))

# mqtt/validators.py:136-138 - Parsea OTRA VEZ en to_ingest_row
datetime.fromisoformat(self.timestamp.replace("Z", "+00:00"))
```

**Soluci√≥n:** Parsear una vez y cachear.

## 4.4 Serializaci√≥n Ineficiente

### Problema: JSON parsing sin orjson
```python
# mqtt/receiver.py usa json.loads() est√°ndar
# orjson es 3-10x m√°s r√°pido
```

## 4.5 Uso de Redis

### ‚úÖ Correcto: Throttling por sensor
```python
# broker/throttled.py - Evita spam al broker
```

### ‚ö†Ô∏è Mejorable: Sin pipeline para batch
```python
# Cada lectura hace un XADD individual
# Deber√≠a usar pipeline para batch
```

---

# 5. ESTRUCTURA

## 5.1 Nombres de Carpetas Problem√°ticos

| Carpeta | Problema | Sugerencia |
|---------|----------|------------|
| `ingest/` | Confuso con el servicio `ingest_api` | `pipelines/` |
| `ingest/common/` | Demasiado gen√©rico | `ingest/validation/` |
| `ingest/handlers/` | Solo tiene `batch.py` | Mover a `ingest/` |
| `core/` | Existe pero poco usado | Integrar o eliminar |
| `mqtt/` | Mezcla receiver + validators | Separar |

## 5.2 Separaci√≥n por Responsabilidad

### Actual (Problem√°tico)
```
ingest_api/
‚îú‚îÄ‚îÄ ingest/           # L√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ router.py     # Orquestaci√≥n + SP + broker
‚îÇ   ‚îú‚îÄ‚îÄ common/       # Validaci√≥n + queries + utils
‚îÇ   ‚îî‚îÄ‚îÄ handlers/     # Solo batch.py
‚îú‚îÄ‚îÄ mqtt/             # Transporte + validaci√≥n
‚îú‚îÄ‚îÄ endpoints/        # HTTP handlers
‚îú‚îÄ‚îÄ classification/   # ML + estados
‚îî‚îÄ‚îÄ broker/           # Redis abstraction
```

### Propuesto
```
ingest_api/
‚îú‚îÄ‚îÄ transport/        # Capa de transporte
‚îÇ   ‚îú‚îÄ‚îÄ http/         # FastAPI endpoints
‚îÇ   ‚îú‚îÄ‚îÄ mqtt/         # MQTT receiver
‚îÇ   ‚îî‚îÄ‚îÄ contracts/    # DTOs unificados
‚îú‚îÄ‚îÄ domain/           # L√≥gica de negocio pura
‚îÇ   ‚îú‚îÄ‚îÄ classification/
‚îÇ   ‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îî‚îÄ‚îÄ state/
‚îú‚îÄ‚îÄ infrastructure/   # Adaptadores externos
‚îÇ   ‚îú‚îÄ‚îÄ database/     # SP executor, queries
‚îÇ   ‚îú‚îÄ‚îÄ redis/        # Broker, cache
‚îÇ   ‚îî‚îÄ‚îÄ metrics/
‚îî‚îÄ‚îÄ application/      # Casos de uso
    ‚îú‚îÄ‚îÄ ingest_reading.py
    ‚îî‚îÄ‚îÄ batch_ingest.py
```

## 5.3 Dependencias Circulares Potenciales

```
ingest/common/validation.py
    ‚Üí imports classification.SensorStateManager
    
classification/reading_classifier.py
    ‚Üí imports ingest/common/validation (indirectamente via guards)
```

**Riesgo:** Import circular si se reorganiza sin cuidado.

---

# 6. FALENCIAS CR√çTICAS

## 6.1 T√©cnicas

| ID | Falencia | Severidad | Archivo |
|----|----------|-----------|---------|
| T1 | Sin retry en SP | üî¥ ALTA | `router.py` |
| T2 | Parsing repetido de timestamp | ‚ö†Ô∏è MEDIA | `validators.py` |
| T3 | Lock global en buffer | ‚ö†Ô∏è MEDIA | `batch_inserter.py` |
| T4 | Import dentro de m√©todo | ‚ö†Ô∏è MEDIA | `router.py:158` |
| T5 | Catch gen√©rico silencioso | ‚ö†Ô∏è MEDIA | Varios |

## 6.2 Arquitectura

| ID | Falencia | Severidad | Impacto |
|----|----------|-----------|---------|
| A1 | Sin deduplicaci√≥n | üî¥ ALTA | Datos duplicados |
| A2 | Sin dead letter queue | üî¥ ALTA | P√©rdida de datos |
| A3 | DTOs inconsistentes | ‚ö†Ô∏è MEDIA | Bugs de integraci√≥n |
| A4 | Archivos >180 l√≠neas | ‚ö†Ô∏è MEDIA | Mantenibilidad |
| A5 | Nombres confusos | ‚ö†Ô∏è BAJA | Onboarding lento |

## 6.3 Contratos

| ID | Falencia | Severidad | Canal |
|----|----------|-----------|-------|
| C1 | sensor_id: int vs string | ‚ö†Ô∏è MEDIA | HTTP vs MQTT |
| C2 | timestamp: float vs ISO | ‚ö†Ô∏è MEDIA | HTTP vs MQTT |
| C3 | Sin DTO para Redis | ‚ö†Ô∏è MEDIA | Redis Streams |
| C4 | metadata sin validaci√≥n | ‚ö†Ô∏è MEDIA | MQTT |

## 6.4 Rendimiento

| ID | Falencia | Severidad | Impacto |
|----|----------|-----------|---------|
| R1 | SP s√≠ncrono en request | ‚ö†Ô∏è MEDIA | Latencia alta |
| R2 | Sin batch para Redis | ‚ö†Ô∏è BAJA | Throughput limitado |
| R3 | json vs orjson | ‚ö†Ô∏è BAJA | CPU innecesario |

---

# 7. PLAN DE MEJORA

## 7.1 Prioridad ALTA (Sprint 1)

### 7.1.1 Implementar Deduplicaci√≥n
```python
# Nuevo: ingest/deduplication.py
class MessageDeduplicator:
    def __init__(self, redis: Redis, ttl_seconds: int = 300):
        self._redis = redis
        self._ttl = ttl_seconds
    
    def is_duplicate(self, msg_id: str) -> bool:
        key = f"msg:seen:{msg_id}"
        result = self._redis.set(key, "1", nx=True, ex=self._ttl)
        return result is None  # None = ya exist√≠a
```

### 7.1.2 Implementar Dead Letter Queue
```python
# Nuevo: ingest/dead_letter.py
class DeadLetterQueue:
    STREAM_NAME = "dlq:ingest"
    
    def send(self, payload: dict, error: str, source: str):
        self._redis.xadd(self.STREAM_NAME, {
            "payload": json.dumps(payload),
            "error": error,
            "source": source,
            "timestamp": time.time(),
        })
```

### 7.1.3 Agregar Retry con Backoff
```python
# Modificar: ingest/router.py
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=0.5, min=0.5, max=5),
    reraise=True,
)
def _execute_sp(self, sensor_id: int, value: float, device_ts: datetime):
    self._db.execute(text("EXEC sp_insert_reading..."), {...})
```

## 7.2 Prioridad MEDIA (Sprint 2)

### 7.2.1 Unificar DTOs
```python
# Nuevo: transport/contracts/reading.py
from pydantic import BaseModel, Field, validator
from datetime import datetime
from typing import Optional

class UnifiedReading(BaseModel):
    """DTO unificado para todas las fuentes."""
    sensor_id: int = Field(..., ge=1)
    value: float
    timestamp: float  # Unix epoch
    sensor_type: Optional[str] = None
    sequence: Optional[int] = None
    msg_id: Optional[str] = None
    
    @validator("value")
    def validate_value(cls, v):
        if v != v:  # NaN
            raise ValueError("Value is NaN")
        return v
    
    @classmethod
    def from_mqtt(cls, payload: MQTTReadingPayload) -> "UnifiedReading":
        return cls(
            sensor_id=payload.sensor_id_int,
            value=payload.value,
            timestamp=payload.timestamp_float,
            sensor_type=payload.sensor_type,
            sequence=payload.sequence,
            msg_id=payload.msg_id,
        )
    
    @classmethod
    def from_http(cls, reading: SensorReadingUuidIn, sensor_id: int) -> "UnifiedReading":
        return cls(
            sensor_id=sensor_id,
            value=reading.value,
            timestamp=reading.sensor_ts or time.time(),
            sequence=reading.sequence,
        )
```

### 7.2.2 Refactorizar Archivos Grandes

| Archivo | Acci√≥n |
|---------|--------|
| `ingestion_metrics.py` (349) | Separar en `sensor_stats.py` + `aggregator.py` |
| `alert_persistence.py` (270) | Separar en `alert_repo.py` + `notification_service.py` |
| `validation.py` (250) | Separar en `validators.py` + `threshold_queries.py` |
| `receiver.py` (246) | Separar en `mqtt_client.py` + `message_handler.py` |

### 7.2.3 Cachear Timestamp Parseado
```python
# ANTES (mqtt/validators.py)
@property
def timestamp_float(self) -> float:
    dt = datetime.fromisoformat(self.timestamp.replace("Z", "+00:00"))
    return dt.timestamp()

# DESPU√âS
class MQTTReadingPayload(BaseModel):
    _parsed_ts: Optional[float] = None
    
    @validator("timestamp")
    def validate_and_parse_timestamp(cls, v):
        dt = datetime.fromisoformat(v.replace("Z", "+00:00"))
        # Validaciones...
        return v
    
    def __init__(self, **data):
        super().__init__(**data)
        dt = datetime.fromisoformat(self.timestamp.replace("Z", "+00:00"))
        object.__setattr__(self, "_parsed_ts", dt.timestamp())
    
    @property
    def timestamp_float(self) -> float:
        return self._parsed_ts
```

## 7.3 Prioridad BAJA (Sprint 3)

### 7.3.1 Renombrar Carpetas
```
ingest/ ‚Üí pipelines/
ingest/common/ ‚Üí pipelines/validation/
ingest/handlers/ ‚Üí (eliminar, mover batch.py)
```

### 7.3.2 Usar orjson
```python
# requirements.txt
orjson>=3.9.0

# mqtt/receiver.py
import orjson

def _parse_json(self, payload: bytes, topic: str) -> Optional[dict]:
    try:
        return orjson.loads(payload)
    except orjson.JSONDecodeError as e:
        ...
```

### 7.3.3 Pipeline Redis para Batch
```python
# broker/redis_broker.py
def publish_batch(self, readings: List[Reading]):
    pipe = self._redis.pipeline()
    for r in readings:
        pipe.xadd(self._stream, r.to_dict())
    pipe.execute()
```

---

# 8. RIESGOS SI NO SE CORRIGE

| Riesgo | Probabilidad | Impacto | Consecuencia |
|--------|--------------|---------|--------------|
| Lecturas duplicadas | ALTA | MEDIO | Alertas falsas, m√©tricas incorrectas |
| P√©rdida de datos (sin DLQ) | MEDIA | ALTO | Datos perdidos sin trazabilidad |
| Timeout en ingesta | MEDIA | MEDIO | P√©rdida de lecturas en picos |
| Delta spike incorrecto (OOO) | MEDIA | ALTO | Alertas falsas |
| Bugs por DTOs inconsistentes | ALTA | BAJO | Tiempo de debugging |

---

# 9. EJEMPLOS ANTES ‚Üí DESPU√âS

## 9.1 Deduplicaci√≥n

### ANTES
```python
def _on_message(self, client, userdata, msg):
    data = self._parse_json(msg.payload, msg.topic)
    if data is None:
        return
    # Procesa sin verificar duplicados
    self._processor.process(data)
```

### DESPU√âS
```python
def _on_message(self, client, userdata, msg):
    data = self._parse_json(msg.payload, msg.topic)
    if data is None:
        self._dlq.send(msg.payload, "parse_error", "mqtt")
        return
    
    msg_id = data.get("msgId") or f"{data.get('sensorId')}:{data.get('timestamp')}"
    if self._dedup.is_duplicate(msg_id):
        self._stats.duplicates += 1
        return
    
    self._processor.process(data)
```

## 9.2 Retry con Backoff

### ANTES
```python
try:
    self._db.execute(text("EXEC sp_insert_reading..."), params)
except Exception as e:
    self._logger.exception("INGEST ERROR SP...")
    raise
```

### DESPU√âS
```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=0.5, min=0.5, max=5),
    before_sleep=lambda retry_state: logger.warning(
        "SP retry %d for sensor_id=%s", 
        retry_state.attempt_number, 
        retry_state.args[0]
    ),
)
def _execute_sp(self, sensor_id: int, value: float, device_ts: datetime):
    self._db.execute(text("EXEC sp_insert_reading..."), {
        "sensor_id": sensor_id,
        "value": value,
        "device_ts": device_ts,
    })
```

## 9.3 DTO Unificado

### ANTES
```python
# HTTP endpoint
row = {"sensor_id": sensor_id, "value": float(r.value)}
if r.sensor_ts is not None:
    row["sensor_ts"] = r.sensor_ts
    row["device_timestamp"] = datetime.fromtimestamp(r.sensor_ts, tz=timezone.utc)

# MQTT handler
row = payload.to_ingest_row()  # Formato diferente
```

### DESPU√âS
```python
# HTTP endpoint
reading = UnifiedReading.from_http(r, sensor_id)

# MQTT handler
reading = UnifiedReading.from_mqtt(payload)

# Ambos usan el mismo formato
self._processor.process(reading)
```

---

# 10. CONCLUSI√ìN

El m√≥dulo de ingesta **funciona** pero tiene deuda t√©cnica significativa en:

1. **Resiliencia**: Sin deduplicaci√≥n, retry ni DLQ
2. **Contratos**: DTOs inconsistentes entre canales
3. **Mantenibilidad**: Archivos grandes, responsabilidades mezcladas

**Recomendaci√≥n**: Priorizar Sprint 1 (deduplicaci√≥n + DLQ + retry) antes de agregar nuevas funcionalidades.

---

# 11. CORRECCIONES IMPLEMENTADAS (2026-02-02)

## 11.1 Archivos Creados

| Archivo | Descripci√≥n |
|---------|-------------|
| `ingest/resilience/__init__.py` | M√≥dulo de resiliencia |
| `ingest/resilience/deduplication.py` | `MessageDeduplicator` con Redis SET + TTL |
| `ingest/resilience/dead_letter.py` | `DeadLetterQueue` con Redis Streams |
| `ingest/resilience/retry.py` | `retry_with_backoff` decorador + `RetryConfig` |
| `ingest/resilience/factory.py` | Factory para inicializar componentes |
| `ingest/contracts/__init__.py` | M√≥dulo de contratos |
| `ingest/contracts/unified_reading.py` | `UnifiedReading` DTO unificado |
| `endpoints/resilience_health.py` | Endpoint `/health/resilience` |

## 11.2 Archivos Modificados

| Archivo | Cambios |
|---------|---------|
| `ingest/router.py` | + Retry con backoff, + deduplicaci√≥n, + DLQ, + stats |
| `ingest/handlers/batch.py` | + Soporte para deduplicador y DLQ |
| `mqtt/validators.py` | + Cache de timestamp parseado (evita 3x parsing) |
| `mqtt/receiver.py` | + Integraci√≥n con deduplicaci√≥n y DLQ |
| `endpoints/packet_ingest.py` | + Uso de componentes de resiliencia |

## 11.3 Configuraci√≥n via Variables de Entorno

```bash
# Redis
REDIS_URL=redis://localhost:6379/0
REDIS_ENABLED=true

# Deduplicaci√≥n
DEDUP_ENABLED=true
DEDUP_TTL_SECONDS=300

# Dead Letter Queue
DLQ_ENABLED=true
DLQ_STREAM_NAME=dlq:ingest
DLQ_MAX_LEN=10000
```

## 11.4 Estado de Correcciones

| ID | Falencia | Estado |
|----|----------|--------|
| T1 | Sin retry en SP | ‚úÖ CORREGIDO |
| T2 | Parsing repetido de timestamp | ‚úÖ CORREGIDO |
| A1 | Sin deduplicaci√≥n | ‚úÖ CORREGIDO |
| A2 | Sin dead letter queue | ‚úÖ CORREGIDO |
| C1-C4 | DTOs inconsistentes | ‚úÖ CORREGIDO (UnifiedReading) |

## 11.5 Sprint 2-3 Completado (2026-02-02)

### Archivos Refactorizados

| Archivo Original | L√≠neas | Nuevos M√≥dulos |
|------------------|--------|----------------|
| `metrics/ingestion_metrics.py` | 349‚Üí19 | `sensor_stats.py` (120), `aggregator.py` (190) |
| `ingest/alerts/alert_persistence.py` | 298‚Üí90 | `alert_repository.py` (180), `notification_service.py` (100) |
| `ingest/common/validation.py` | 300‚Üí180 | `threshold_queries.py` (80), `suspicious_readings.py` (65) |

### Mejoras de Rendimiento

| Cambio | Archivo | Beneficio |
|--------|---------|-----------|
| orjson para JSON parsing | `mqtt/receiver.py` | 3-10x m√°s r√°pido |
| Cache de timestamp | `mqtt/validators.py` | Evita 3x parsing |

### Archivos Creados (Sprint 2-3)

```
ingest_api/
‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îú‚îÄ‚îÄ sensor_stats.py      # 120 l√≠neas - Stats por sensor
‚îÇ   ‚îî‚îÄ‚îÄ aggregator.py        # 190 l√≠neas - Servicio agregador
‚îú‚îÄ‚îÄ ingest/
‚îÇ   ‚îú‚îÄ‚îÄ alerts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alert_repository.py      # 180 l√≠neas - Operaciones BD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ notification_service.py  # 100 l√≠neas - Push notifications
‚îÇ   ‚îî‚îÄ‚îÄ common/
‚îÇ       ‚îú‚îÄ‚îÄ threshold_queries.py     # 80 l√≠neas - Consultas umbrales
‚îÇ       ‚îî‚îÄ‚îÄ suspicious_readings.py   # 65 l√≠neas - Detecci√≥n zeros
```

## 11.6 Pendientes Futuros

- [ ] Renombrar carpetas confusas (`ingest/` ‚Üí `pipelines/`)
- [ ] Pipeline Redis para batch inserts
